#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–∞–∑–±–æ—Ä–∞ baza.txt –Ω–∞ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º —Ä–∞–∑–¥–µ–ª–∞–º.
–°–æ–∑–¥–∞–µ—Ç –ø–∞–ø–∫—É baza/ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞–∑–¥–µ–ª—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã.
"""

import os
import re
from pathlib import Path


def split_baza_file():
    """–†–∞–∑–±–∏–≤–∞–µ—Ç baza.txt –Ω–∞ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã"""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    input_file = "baza.txt"
    output_dir = "baza"
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ —Å –∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    sections = {
        "fpf_pattern": {
            "name": "FPF Pattern - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞",
            "file": "01_fpf_pattern.txt",
            "keywords": ["–ü–†–ê–í–ò–õ–¨–ù–û–ï –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï", "FIX-PREFIX", "–®–û–†–¢–û–í–´–ô", "–ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–¨"]
        },
        "philosophy": {
            "name": "–§–∏–ª–æ—Å–æ—Ñ–∏—è –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞", 
            "file": "02_philosophy.txt",
            "keywords": ["–§–ò–õ–û–°–û–§–ò–Ø", "–ö–û–ù–¶–ï–ü–¶–ò–Ø", "–¢–û–†–ì–û–í–ê–Ø –§–ò–õ–û–°–û–§–ò–Ø", "–ü–°–ò–•–û–õ–û–ì–ò–Ø"]
        },
        "architecture": {
            "name": "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã",
            "file": "03_architecture.txt", 
            "keywords": ["–ê–†–•–ò–¢–ï–ö–¢–£–†–ê", "–ü–û–¢–û–ö –î–ê–ù–ù–´–•", "–°–¢–†–£–ö–¢–£–†–ê"]
        },
        "stream_core": {
            "name": "StreamCore - –§—É–Ω–¥–∞–º–µ–Ω—Ç —Å–∏—Å—Ç–µ–º—ã",
            "file": "04_stream_core.txt",
            "keywords": ["–ú–û–î–£–õ–¨ 1", "StreamCore", "–§–£–ù–î–ê–ú–ï–ù–¢ –°–ò–°–¢–ï–ú–´"]
        },
        "level_engine": {
            "name": "LevelEngine - –†—ã–Ω–æ—á–Ω—ã–µ —É—Ä–æ–≤–Ω–∏",
            "file": "05_level_engine.txt", 
            "keywords": ["–ú–û–î–£–õ–¨ 2", "LevelEngine", "–†–´–ù–û–ß–ù–´–• –£–†–û–í–ù–ï–ô"]
        },
        "fpf_detector": {
            "name": "FPFDetector - –°–µ—Ä–¥—Ü–µ —Å–∏—Å—Ç–µ–º—ã",
            "file": "06_fpf_detector.txt",
            "keywords": ["–ú–û–î–£–õ–¨ 3", "FPFDetector", "–°–ï–†–î–¶–ï –°–ò–°–¢–ï–ú–´"]
        },
        "context_filters": {
            "name": "ContextFilters - –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤",
            "file": "07_context_filters.txt",
            "keywords": ["–ú–û–î–£–õ–¨ 4", "ContextFilters", "–§–ò–õ–¨–¢–†–ê–¶–ò–Ø –°–ò–ì–ù–ê–õ–û–í"]
        },
        "signal_manager": {
            "name": "SignalManager - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞–º–∏", 
            "file": "08_signal_manager.txt",
            "keywords": ["–ú–û–î–£–õ–¨ 5", "SignalManager", "–£–ü–†–ê–í–õ–ï–ù–ò–ï –°–ò–ì–ù–ê–õ–ê–ú–ò"]
        },
        "ui_system": {
            "name": "UI/UX —Å–∏—Å—Ç–µ–º–∞",
            "file": "09_ui_system.txt",
            "keywords": ["–ú–û–î–£–õ–¨ 6", "UI/UX", "–ò–ù–¢–ï–†–§–ï–ô–°"]
        },
        "backtest": {
            "name": "BacktestRunner - –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π",
            "file": "10_backtest.txt", 
            "keywords": ["–ú–û–î–£–õ–¨ 7", "BacktestRunner", "–í–ê–õ–ò–î–ê–¶–ò–Ø –°–¢–†–ê–¢–ï–ì–ò–ô"]
        },
        "machine_learning": {
            "name": "–°–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏",
            "file": "11_machine_learning.txt",
            "keywords": ["–ú–û–î–£–õ–¨ 8", "–û–ë–£–ß–ï–ù–ò–Ø", "–ê–î–ê–ü–¢–ê–¶–ò–ò"]
        },
        "monitoring": {
            "name": "–°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –∞–ª–µ—Ä—Ç–æ–≤",
            "file": "12_monitoring.txt",
            "keywords": ["–ú–û–ù–ò–¢–û–†–ò–ù–ì–ê", "–ê–õ–ï–†–¢–û–í"]
        },
        "integrations": {
            "name": "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏", 
            "file": "13_integrations.txt",
            "keywords": ["–ò–ù–¢–ï–ì–†–ê–¶–ò–Ø", "–í–ù–ï–®–ù–ò–ú–ò –°–ò–°–¢–ï–ú–ê–ú–ò"]
        },
        "deployment": {
            "name": "–ü–ª–∞–Ω —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏",
            "file": "14_deployment.txt",
            "keywords": ["–†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–Ø", "–≠–ö–°–ü–õ–£–ê–¢–ê–¶–ò–ò"]
        },
        "technical_requirements": {
            "name": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞",
            "file": "15_technical_requirements.txt", 
            "keywords": ["–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø", "–ù–ê–°–¢–†–û–ô–ö–ê", "–°–ò–°–¢–ï–ú–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø"]
        },
        "development_plan": {
            "name": "–ü–ª–∞–Ω –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è",
            "file": "16_development_plan.txt",
            "keywords": ["–î–ê–õ–¨–ù–ï–ô–®–ï–ì–û –†–ê–ó–í–ò–¢–ò–Ø", "–§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò"]
        },
        "technical_issues": {
            "name": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è",
            "file": "17_technical_issues.txt",
            "keywords": ["–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´", "–†–ï–®–ï–ù–ò–Ø", "OCR", "–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"]
        }
    }
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if not os.path.exists(input_file):
        print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–∏
    Path(output_dir).mkdir(exist_ok=True)
    
    print(f"üîÑ –ß–∏—Ç–∞—é {input_file}...")
    with open(input_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    lines = content.split('\n')
    total_lines = len(lines)
    
    print(f"üìÑ –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total_lines}")
    
    # –ü–æ–∏—Å–∫ –≥—Ä–∞–Ω–∏—Ü —Ä–∞–∑–¥–µ–ª–æ–≤ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
    section_boundaries = []
    
    for i, line in enumerate(lines):
        # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∞–∑–¥–µ–ª–æ–≤
        if re.match(r'^# (–ú–û–î–£–õ–¨|–ü–†–ê–í–ò–õ–¨–ù–û–ï|–§–ò–õ–û–°–û–§–ò–Ø|–°–ò–°–¢–ï–ú–ê|–ò–ù–¢–ï–ì–†–ê–¶–ò–Ø|–ü–õ–ê–ù|–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï|–§–ò–ù–ê–õ–¨–ù–´–ï)', line):
            section_boundaries.append((i, line.strip()))
    
    section_boundaries.append((total_lines, "# END"))  # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞
    
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(section_boundaries)-1}")
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤
    for i in range(len(section_boundaries)-1):
        start_line = section_boundaries[i][0]
        end_line = section_boundaries[i+1][0]
        section_title = section_boundaries[i][1]
        
        section_content = lines[start_line:end_line]
        section_text = '\n'.join(section_content)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ä–∞–∑–¥–µ–ª–∞ –∏ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        section_key = None
        output_file = None
        
        for key, meta in sections.items():
            if any(keyword in section_title for keyword in meta["keywords"]):
                section_key = key
                output_file = meta["file"]
                break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, —Å–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –ø–æ –Ω–æ–º–µ—Ä—É
        if not output_file:
            section_num = str(i+1).zfill(2)
            clean_title = re.sub(r'[^\w\s-]', '', section_title).strip()
            clean_title = re.sub(r'\s+', '_', clean_title)[:50]
            output_file = f"{section_num}_{clean_title}.txt"
        
        output_path = os.path.join(output_dir, output_file)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–ª—è —Ñ–∞–π–ª–∞
        file_header = f"""# {section_title}
# –ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ baza.txt (—Å—Ç—Ä–æ–∫–∏ {start_line+1}-{end_line})
# –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

"""
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(file_header + section_text)
        
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file} ({len(section_content)} —Å—Ç—Ä–æ–∫)")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    create_index_file(output_dir, sections)
    
    print(f"üéâ –ì–æ—Ç–æ–≤–æ! –°–æ–∑–¥–∞–Ω–æ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ {output_dir}/")


def create_index_file(output_dir, sections):
    """–°–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å–Ω—ã–π —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –≤—Å–µ—Ö —Ä–∞–∑–¥–µ–ª–æ–≤"""
    
    index_content = f"""# –ò–ù–î–ï–ö–° –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô FPF BOT
# –°–æ–∑–¥–∞–Ω: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

–≠—Ç–æ—Ç –∫–∞—Ç–∞–ª–æ–≥ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞–∑–±–∏—Ç—É—é –Ω–∞ —Ä–∞–∑–¥–µ–ª—ã –±–∞–∑—É –∑–Ω–∞–Ω–∏–π FPF Bot.

## –°–¢–†–£–ö–¢–£–†–ê –§–ê–ô–õ–û–í:

"""
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ
    files_in_dir = sorted([f for f in os.listdir(output_dir) if f.endswith('.txt')])
    
    for filename in files_in_dir:
        if filename == '00_INDEX.txt':
            continue
            
        # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –≤ sections
        section_name = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–∞–∑–¥–µ–ª"
        for key, meta in sections.items():
            if meta["file"] == filename:
                section_name = meta["name"]
                break
        
        index_content += f"- `{filename}` - {section_name}\n"
    
    index_content += f"""
## –ö–ê–ö –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨:

1. –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–∞–π–ª—ã –ø–æ –Ω–æ–º–µ—Ä–∞–º –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è
2. –ö–∞–∂–¥—ã–π —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Å–≤–æ–µ–π —Ç–µ–º–µ
3. –ù–∞—á–Ω–∏ —Å `01_fpf_pattern.txt` –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –æ—Å–Ω–æ–≤
4. –ó–∞—Ç–µ–º –∏–∑—É—á–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –≤ `03_architecture.txt` –∏ `04_stream_core.txt`

## –ë–´–°–¢–†–´–ô –ü–û–ò–°–ö:

- **–ü–∞—Ç—Ç–µ—Ä–Ω FPF**: `01_fpf_pattern.txt`
- **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: `03_architecture.txt`, `04_stream_core.txt`
- **–î–µ—Ç–µ–∫—Ç–æ—Ä—ã**: `06_fpf_detector.txt`, `07_context_filters.txt`
- **UI –∏ –∞–ª–µ—Ä—Ç—ã**: `09_ui_system.txt`, `12_monitoring.txt`
- **–ü—Ä–æ–±–ª–µ–º—ã**: `17_technical_issues.txt`
"""
    
    index_path = os.path.join(output_dir, "00_INDEX.txt")
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(index_content)


if __name__ == "__main__":
    split_baza_file()